# -*- coding: utf-8 -*-
"""Group26_SportsPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Sd9eY8y5azvCMTuZE4AVT2YDzHnbfOOC
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold, cross_val_score, train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
import xgboost as xgb
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV

DatasetFifa21 = pd.read_csv('players_21.csv')

"""**Data Preprocessing**"""

DatasetFifa21.head()

DatasetFifa21.tail()

DatasetFifa21.describe()

DatasetFifa21.info()

#Viewing all the column labels to be able to select the relevant columns
DatasetFifa21.columns.tolist()

#dropping the columns that are immediately evidently irrelevant to a player's overall rating
irrelevant_columns = ['sofifa_id', 'player_url', 'player_face_url', 'club_logo_url', 'club_flag_url', 'nation_logo_url', 'nation_flag_url','dob',
                      'potential', 'club_team_id',	'club_name',	'league_name']
DatasetFifa21.drop(columns=irrelevant_columns, inplace=True)

DatasetFifa21

"""**Feature Selection and Augmentation**"""

#A player's BMI might impact their performance in training, and consequently, actual football games
#A player's BMI might also afect their lower body joints (wear and tear), which would also affect their game availability.
#As such, we aggregate players' heights and weights into a BMI attribute, and then we categorize them. This should allow us
#see if there is colleration between players' overall rating and their BMI
def categorize_bmi(bmi):
    '''This method categorizes a players BMI into one of three categories: underweight, balanced, overweight
    The benchmarks used were sourced from https://sportsmanist.com/how-much-should-a-soccer-player-weigh and
    https://ids-water.com/2021/04/29/what-is-a-good-bmi-for-a-soccer-player/'''
    if bmi < 18.5:
        return 'Underweight'
    elif 20 <= bmi < 24.9:
        return 'Balanced'
    else:
        return 'Overweight'

#Creating a BMI column that contains players' BMIs calculated using each player's height and weight
height_meters = DatasetFifa21['height_cm'] / 100
DatasetFifa21['bmi'] = DatasetFifa21['weight_kg'] / (height_meters ** 2)

#Applying the categorize_bmi tp each player's BMI and creating a new column that contains the category
DatasetFifa21['bmi_category'] = DatasetFifa21['bmi'].apply(categorize_bmi)

DatasetFifa21['player_positions'].fillna('', inplace=True)
non_goalkeeper_df = DatasetFifa21.copy()
#goalkeeper_df = DatasetFifa21[DatasetFifa21['player_positions'].str.startswith('GK')]

#non_golakeeper_df = non_goalkeeper_df.drop(columns = ['goalkeeping_diving','goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning','goalkeeping_reflexes', 'goalkeeping_speed'])

#goalkeeper_df = goalkeeper_df.drop(columns = ['pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic'])

mean = non_goalkeeper_df['goalkeeping_speed'].mean()
non_goalkeeper_df['goalkeeping_speed'].fillna(mean, inplace = True)

'''attributes_to_mean_gk = [
    'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',
    'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve',
    'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control',
    'movement_acceleration', 'movement_sprint_speed', 'movement_agility',
    'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping',
    'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression',
    'mentality_interceptions', 'mentality_positioning', 'mentality_vision',
    'mentality_penalties', 'mentality_composure', 'defending_marking_awareness',
    'defending_standing_tackle', 'defending_sliding_tackle', 'goalkeeping_diving',
    'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning',
    'goalkeeping_reflexes', 'goalkeeping_speed'
]'''

attributes_to_mean_non_gk = [
    'pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic',
    'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',
    'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve',
    'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control',
    'movement_acceleration', 'movement_sprint_speed', 'movement_agility',
    'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping',
    'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression',
    'mentality_interceptions', 'mentality_positioning', 'mentality_vision',
    'mentality_penalties', 'mentality_composure', 'defending_marking_awareness',
    'defending_standing_tackle', 'defending_sliding_tackle','goalkeeping_diving',
    'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning',
    'goalkeeping_reflexes', 'goalkeeping_speed'
]

non_goalkeeper_df['mean_attributes'] = non_goalkeeper_df[attributes_to_mean_non_gk].mean(axis = 1)
#goalkeeper_df['mean_attributes'] = non_goalkeeper_df[attributes_to_mean_gk].mean(axis = 1)

'''selected_features_gk = [
    'short_name', 'long_name', 'league_level', 'weak_foot', 'skill_moves', 'international_reputation',
    'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',
    'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve',
    'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control',
    'movement_acceleration', 'movement_sprint_speed', 'movement_agility',
    'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping',
    'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression',
    'mentality_interceptions', 'mentality_positioning', 'mentality_vision',
    'mentality_penalties', 'mentality_composure', 'defending_marking_awareness',
    'defending_standing_tackle', 'defending_sliding_tackle', 'goalkeeping_diving',
    'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning',
    'goalkeeping_reflexes', 'goalkeeping_speed','bmi_category', 'value_eur',
    'wage_eur', 'release_clause_eur','age','mean_attributes', 'overall'
]'''
selected_features_non_gk = [
    'short_name', 'long_name', 'league_level', 'weak_foot', 'skill_moves', 'international_reputation',
    'pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic',
    'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',
    'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve',
    'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control',
    'movement_acceleration', 'movement_sprint_speed', 'movement_agility',
    'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping',
    'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression',
    'mentality_interceptions', 'mentality_positioning', 'mentality_vision',
    'mentality_penalties', 'mentality_composure', 'defending_marking_awareness',
    'defending_standing_tackle', 'defending_sliding_tackle','bmi_category', 'value_eur',
    'wage_eur', 'release_clause_eur', 'goalkeeping_diving',
    'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning',
    'goalkeeping_reflexes', 'goalkeeping_speed','age','mean_attributes', 'overall'
]

data = non_goalkeeper_df[selected_features_non_gk].copy()

data.isnull().sum()

#Replacing all NAs with the mean pf the column so they do not significantly impact calculations in later kernels, e.g. mean
#From inspection, the rows in the relevant columns that contain missing values are rows
#that contain numerical data

mean = data['value_eur'].mean()
data['value_eur'].fillna(mean, inplace = True)

mean = data['release_clause_eur'].mean()
data['release_clause_eur'].fillna(mean, inplace = True)

mean = data['wage_eur'].mean()
data['wage_eur'].fillna(mean, inplace = True)

mean = data['league_level'].mean()
data['league_level'].fillna(mean, inplace = True)

mean = data['pace'].mean()
data['pace'].fillna(mean, inplace = True)

mean = data['shooting'].mean()
data['shooting'].fillna(mean, inplace = True)

mean = data['passing'].mean()
data['passing'].fillna(mean, inplace = True)

mean = data['dribbling'].mean()
data['dribbling'].fillna(mean, inplace = True)

mean = data['defending'].mean()
data['defending'].fillna(mean, inplace = True)

mean = data['physic'].mean()
data['physic'].fillna(mean, inplace = True)

data.head()

data.tail()

data.columns.tolist()

print(data.isnull().sum(), "\n\n")

# Extract the independent variables
independent_variables = data.drop(columns=['overall', 'short_name', 'long_name'])

# Extract the dependent variable
dependent_variable = data['overall']

# Calculate the correlation matrix
correlation_matrix = independent_variables.corrwith(dependent_variable)

# Sort the correlations in descending order
sorted_correlations = correlation_matrix.abs().sort_values(ascending=False)

# Select the top 10 features with the highest correlation
n_top_features = 16
top_features = sorted_correlations[:n_top_features]

# Visualize the top correlated features
plt.figure(figsize=(12, 8))
sns.barplot(x=top_features, y=top_features.index, palette="Blues_d")
plt.title("Top Correlated Features with Overall Rating")
plt.xlabel("Correlation")
plt.ylabel("Feature")
plt.show()

# Create feature subsets using the top correlated features
feature_subsets = data[top_features.index]

# Scale the independent variables
scaler = MinMaxScaler()
scaled_features = scaler.fit_transform(feature_subsets)

# Create a DataFrame with scaled features
scaled_df = pd.DataFrame(scaled_features, columns=feature_subsets.columns)

scaled_df.reset_index(drop=True, inplace=True)
dependent_variable.reset_index(drop=True, inplace=True)

# Combine scaled features with the dependent variable
final_data = pd.concat([scaled_df, dependent_variable],axis = 1)

final_data

"""**Model Development**"""

final_data.columns.tolist()

X = final_data.drop(columns=['overall'])
y = final_data['overall']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

n_folds = 10
kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)

#Random Forest Regressor
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_scores = cross_val_score(rf_model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')
rf_rmse = np.sqrt(-rf_scores.mean())

rf_model.fit(X_train, y_train)
score = rf_model.score(X_test, y_test)
mse = mean_squared_error(y_test, rf_model.predict(X_test))

print("RMSE: %.4f" % mse)
print("size of prediction: ", len(rf_model.predict(X_test)))
print("prediction: \n", rf_model.predict(X_test))
print("test score: {0:.4f}\n".format(score))

#XGBoost Regressor
xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')
xgb_rmse = np.sqrt(-xgb_scores.mean())
xgb_model.fit(X_train, y_train)
score = xgb_model.score(X_test, y_test)
mse = mean_squared_error(y_test, xgb_model.predict(X_test))

print("RMSE: %.4f" % mse)
print("size of prediction: ", len(xgb_model.predict(X_test)))
print("prediction: \n", xgb_model.predict(X_test))
print("test score: {0:.4f}\n".format(score))

#Gradient Boosting Regressor
gb_model = GradientBoostingRegressor(n_estimators=500, random_state=42, max_depth=4, min_samples_split=2, learning_rate=0.01)
gb_scores = cross_val_score(gb_model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')
gb_rmse = np.sqrt(-gb_scores.mean())
gb_model.fit(X_train, y_train)
score = gb_model.score(X_test, y_test)
mse = mean_squared_error(y_test, gb_model.predict(X_test))

print("RMSE: %.4f" % mse)
print("size of prediction: ", len(gb_model.predict(X_test)))
print("prediction: \n", gb_model.predict(X_test))
print("test score: {0:.4f}\n".format(score))

dt_model = DecisionTreeRegressor()
param_grid = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [1.0, 'sqrt', 'log2']
}
grid_search = GridSearchCV(dt_model, param_grid, cv=kf, scoring='neg_mean_squared_error')
gs_scores = cross_val_score(dt_model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')
gs_rmse = np.sqrt(-gs_scores.mean())
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
best_dt_model = grid_search.best_estimator_

score = best_dt_model.score(X_test, y_test)
mse = mean_squared_error(y_test, best_dt_model.predict(X_test))

print("MSE: %.4f" % mse)
print("size of prediction: ", len(best_dt_model.predict(X_test)))
print("prediction: \n", best_dt_model.predict(X_test))
print("test score: {0:.4f}\n".format(score))

"""**Optimization**"""

params = {'n_estimators': 7500, 'max_depth': 4, 'min_samples_split': 2,
          'learning_rate': 0.01, 'loss': 'squared_error'}
improved_gbr = GradientBoostingRegressor(**params)

improved_gbr.fit(X_train, y_train)

score = improved_gbr.score(X_test, y_test)

# calculate the Mean Squared Error
mse = mean_squared_error(y_test, improved_gbr.predict(X_test))

print("MSE: %.4f" % mse)
print("size of prediction: ", len(improved_gbr.predict(X_test)))
print("prediction: \n", improved_gbr.predict(X_test))
print("test score: {0:.4f}\n".format(score))

params = {'n_estimators': 7500, 'max_depth': 4, 'learning_rate': 0.01}

improved_xgb = xgb.XGBRegressor(**params)

improved_xgb.fit(X_train, y_train)

score = improved_xgb.score(X_test, y_test)

# calculate the Mean Squared Error
mse = mean_squared_error(y_test, improved_xgb.predict(X_test))

print("MSE: %.4f" % mse)
print("size of prediction: ", len(improved_xgb.predict(X_test)))
print("prediction: \n", improved_xgb.predict(X_test))
print("test score: {0:.4f}\n".format(score))

"""**Ensembling**"""

ensemble = VotingRegressor(estimators=[
    ('improved_gbr', improved_gbr),
    ('improved_xgb', improved_xgb),
    ('rf_model', rf_model),
    ('dt_model', best_dt_model)
])

ensemble.fit(X_train, y_train)
score = ensemble.score(X_test, y_test)


# Make predictions using the ensemble model
y_pred = ensemble.predict(X_test)

# Calculate RMSE (Root Mean Squared Error)
mse = mean_squared_error(y_test, y_pred)

print("MSE: %.4f" % mse)
print("size of prediction: ", len(ensemble.predict(X_test)))
print("prediction: \n", ensemble.predict(X_test))
print("test score: {0:.4f}\n".format(score))

"""**Testing with Fifa 22 Dataset**"""

DatasetFifa22 = pd.read_csv('players_22.csv')

DatasetFifa22.head()

DatasetFifa22.tail()

DatasetFifa22.describe()

irrelevant_columns = ['sofifa_id', 'player_url', 'player_face_url', 'club_logo_url', 'club_flag_url', 'nation_logo_url', 'nation_flag_url','dob',
                      'potential', 'club_team_id',	'club_name',	'league_name']
DatasetFifa22.drop(columns=irrelevant_columns, inplace=True)

DatasetFifa22['player_positions'].fillna('', inplace=True)
training_22_df = DatasetFifa22.copy()

mean = training_22_df['goalkeeping_speed'].mean()
training_22_df['goalkeeping_speed'].fillna(mean, inplace = True)

attributes_to_mean = [
    'pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic',
    'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',
    'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve',
    'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control',
    'movement_acceleration', 'movement_sprint_speed', 'movement_agility',
    'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping',
    'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression',
    'mentality_interceptions', 'mentality_positioning', 'mentality_vision',
    'mentality_penalties', 'mentality_composure', 'defending_marking_awareness',
    'defending_standing_tackle', 'defending_sliding_tackle','goalkeeping_diving',
    'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning',
    'goalkeeping_reflexes', 'goalkeeping_speed'
]

training_22_df['mean_attributes'] = training_22_df[attributes_to_mean].mean(axis = 1)

selected_features = [
    'short_name', 'long_name', 'league_level', 'weak_foot', 'skill_moves', 'international_reputation',
    'pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic',
    'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy',
    'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve',
    'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control',
    'movement_acceleration', 'movement_sprint_speed', 'movement_agility',
    'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping',
    'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression',
    'mentality_interceptions', 'mentality_positioning', 'mentality_vision',
    'mentality_penalties', 'mentality_composure', 'defending_marking_awareness',
    'defending_standing_tackle', 'defending_sliding_tackle','value_eur',
    'wage_eur', 'release_clause_eur', 'goalkeeping_diving',
    'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning',
    'goalkeeping_reflexes', 'goalkeeping_speed','age','mean_attributes', 'overall'
]

data = training_22_df[selected_features].copy()

data.isnull().sum()

mean = data['league_level'].mean()
data['league_level'].fillna(mean, inplace = True)

mean = data['pace'].mean()
data['pace'].fillna(mean, inplace = True)

mean = data['passing'].mean()
data['passing'].fillna(mean, inplace = True)

mean = data['physic'].mean()
data['physic'].fillna(mean, inplace = True)

mean = data['shooting'].mean()
data['shooting'].fillna(mean, inplace = True)

mean = data['defending'].mean()
data['defending'].fillna(mean, inplace = True)

mean = data['dribbling'].mean()
data['dribbling'].fillna(mean, inplace = True)

mean = data['value_eur'].mean()
data['value_eur'].fillna(mean, inplace = True)

mean = data['wage_eur'].mean()
data['wage_eur'].fillna(mean, inplace = True)

mean = data['release_clause_eur'].mean()
data['release_clause_eur'].fillna(mean, inplace = True)

print(data.isnull().sum(), "\n\n")

# Create feature subsets using the top correlated features
feature_subsets = data[['movement_reactions','mentality_composure','passing','mean_attributes','release_clause_eur',
                       'dribbling','wage_eur','power_shot_power','value_eur','mentality_vision','attacking_short_passing',
                       'physic','skill_long_passing','age','shooting','skill_ball_control']]

# Scale the independent variables
scaler = MinMaxScaler()
scaled_features = scaler.fit_transform(feature_subsets)

dependent_variable = data['overall']

# Create a DataFrame with scaled features
scaled_df = pd.DataFrame(scaled_features, columns=feature_subsets.columns)

scaled_df.reset_index(drop=True, inplace=True)
dependent_variable.reset_index(drop=True, inplace=True)

# Combine scaled features with the dependent variable
final_data = pd.concat([scaled_df, dependent_variable],axis = 1)

final_data

X_22 = final_data.drop(columns=['overall'])
y_22 = final_data['overall']

score = ensemble.score(X_22, y_22)


# Make predictions using the ensemble model
y_pred_22 = ensemble.predict(X_22)

# Calculate RMSE (Root Mean Squared Error)
mse = mean_squared_error(y_22, y_pred_22)

print("MSE: %.4f" % mse)
print("size of prediction: ", len(ensemble.predict(X_22)))
print("prediction: \n", ensemble.predict(X_22))
print("test score: {0:.4f}\n".format(score))

score = improved_gbr.score(X_22, y_22)


# Make predictions using the ensemble model
y_pred_22 = improved_gbr.predict(X_22)

# Calculate RMSE (Root Mean Squared Error)
mse = mean_squared_error(y_22, y_pred_22)

print("MSE: %.4f" % mse)
print("size of prediction: ", len(improved_gbr.predict(X_22)))
print("prediction: \n", improved_gbr.predict(X_22))
print("test score: {0:.4f}\n".format(score))

score = rf_model.score(X_22, y_22)


# Make predictions using the ensemble model
y_pred_22 = rf_model.predict(X_22)

# Calculate RMSE (Root Mean Squared Error)
mse = mean_squared_error(y_22, y_pred_22)

print("MSE: %.4f" % mse)
print("size of prediction: ", len(rf_model.predict(X_22)))
print("prediction: \n", rf_model.predict(X_22))
print("test score: {0:.4f}\n".format(score))

score = gb_model.score(X_22, y_22)


# Make predictions using the ensemble model
y_pred_22 = gb_model.predict(X_22)

# Calculate RMSE (Root Mean Squared Error)
mse = mean_squared_error(y_22, y_pred_22)

print("MSE: %.4f" % mse)
print("size of prediction: ", len(gb_model.predict(X_22)))
print("prediction: \n", gb_model.predict(X_22))
print("test score: {0:.4f}\n".format(score))

import pickle
pickle_out = open("classifier.pkl", "wb")
pickle.dump(improved_gbr, pickle_out)
pickle_out.close()